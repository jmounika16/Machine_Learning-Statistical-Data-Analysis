{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align: right;\"> &#9989; **Put your name here** </p>\n",
    "#### <p style=\"text-align: right;\"> &#9989; Put your group member names here</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 17 & 18 In-Class Assignment: The Perceptron Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda for today's class\n",
    "\n",
    "</p>\n",
    "\n",
    "1. [The Perceptron Model](#perceptron)\n",
    "1. [Loading and inspecting the data](#load-data)\n",
    "1. [Build a Perceptron class (first cut)](#build)\n",
    "1. [Visualing our results: plotting the decision boundary](#viz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"perceptron\"></a>\n",
    "## 1. The Perceptron Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perceptron is one of the first used examples of what has come to be called a neural network. Invented in 1958, it was originally hailed as a way to achieve what had come to be called \"Artificial Intelligence\". However, it was quickly proved that the perceptron model was limited. The claims and subsequent refutations halted neural network research for a number of years.\n",
    "\n",
    "Perceptrons are used as a kind of **classifier** that we can train using examples. The simplest perceptron is what is known as a binary classifier. By this we mean that, we can provide individual examples of two classes (hence, a \"binary\" classifier) where the individuals are represented by some number of features/inputs. All examples use the same input features, but the particular feature values are used for the classification process. The goal is the create the classifier such that, when a never-seen-before individual is provided to the perceptron, it can correctly determine that individual's class\n",
    "\n",
    "There are ways to extend the perceptron's ability to deal with multiple classes (to classify the inputs as representing one of `n` classes instead of only two), but for this exercise we will only be concerned with a binary classifer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The limitations of a binary perceptron are that the classes must be **linearly separable**. It is easier to show than to explain. Look at the two graphs below. The axes represent the range of values for the two input features. The dots represent individual input examples based on their corresponding feature values and the colors represent the class that each individual example belongs to. \n",
    "\n",
    "<img src=\"https://i.imgur.com/pU70IHB.png\">\n",
    "\n",
    "For experiment A, it is clear that we can draw a line through the 2D input/feature space such that we can separate the examples of the two classes. For experiment B, no such line separating the two classes exists. Furthermore, it is also clear that we could draw **many** lines for A such that we separate the two classes. \n",
    "\n",
    "**The limitations therefore are**:\n",
    "- a perceptron can only classify elements that are linearly separable\n",
    "- a perceptron cannot distinguish which linear boundary is \"better\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's a line\n",
    "\n",
    "The way to think about what a perceptron is doing then is that it is learning a line through the feature space. We will discuss that in a minute but accepting that is true, what is a line? A line is just a simple equation with the following form:\n",
    "\n",
    "$$y = mx + b $$\n",
    "\n",
    "Where `m` is the slope and `b` is the intercept. We are going to train our perceptron such that it finds `m` and `b` where that particular line separates two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The setup\n",
    "\n",
    "We are going to setup our perceptron as shown in the image below:\n",
    "\n",
    "<img src=\"https://i.imgur.com/gz05jKe.png\">\n",
    "\n",
    "Remembering that each individual example is represented as a set of features, a **vector** of features, we provide a **weight** associated with each feature input. When the features of a individual example is provided, we multipy each input by its associated weight and sum those products together. \n",
    "\n",
    "You may think of this process as multiplying two vectors (the input vector and the weight vector) together, index to index, and summing the resulting products as what is called the **dot product**. You might note that `numpy` provides such a function.\n",
    "\n",
    "Having obtained the dot product of feature inputs and weights, we add what is called a **bias term**. The bias is also associated with a weight (the constant 1 at the top of the inputs) though it's value is constant for all inputs. Altogether the dot product represents the `m` of our line equation and the bias represents the `b` of that equation. \n",
    "\n",
    "Having obtained the result, we pass that result through an **activation function**. Our activation function is typically a step function such that it yields either 1 or -1 indicating whether the particular input is part of one class (1) or the other (-1). Remember, binary classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"load-data\"></a>\n",
    "## 2. Loading and inspecting the data\n",
    "\n",
    "Before we build a machine learning model, we need data to base it off of. The data set we are going to use is available from the course GitHub repository and is called, `binary-iris.csv`.\n",
    "\n",
    "You can download it from: `https://raw.githubusercontent.com/msu-cmse-courses/cmse202-S21-student/master/data/binary-iris.csv`\n",
    "\n",
    "This file is a variation on a classic, simple classification data set for iris flowers from 1936. It is used often as a very simple test of learning systems. The original (see https://en.wikipedia.org/wiki/Iris_flower_data_set ) has 4 classes and 4 inputs, for our experiments we have modified the file to have only 2 inputs and 2 classes. \n",
    "\n",
    "&#9989; **Do This:** Load the data into python and visualize (with a plot) to get a sense for what it looks like. Use different colors to represent the two different iris classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fcef295c198>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do This: Load in the binary-iris.csv file and plot the data based on the iris classifications\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data= pd.read_csv('binary-iris.csv')\n",
    "data.head()\n",
    "\n",
    "grouped= data.groupby('label')\n",
    "\n",
    "for name, group in grouped:\n",
    "    plt.scatter(group.sepal_length, group.sepal_width, marker='o', label=name)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"build\"></a>\n",
    "## 3. Build a Perceptron class (first cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a perceptron class but let's skip the learning process for the moment. We created a \"skeleton\" class for you to fill in.\n",
    "\n",
    "&#9989; **Do This:** Complete these two classes based on the specifications below:\n",
    "\n",
    "- an `__init__` method. Basically every class needs this to set instance attributes (i.e. the variables attached to `self` -- make sure you're using the `self.<variable>` notation!)\n",
    "  - It takes as an argument the labeled data (the two data features plus a data label, -1 or 1, at the end)\n",
    "\n",
    "  - it creates an instance variable `data` for the data passed in from the file. It should contain 2D vector where each row represents an example. The row should consists of two features and a class. The classes should be modified for 1 (iris setosa) and -1 (iris versicolor). \n",
    "\n",
    "  - it creates a 1D weight vector `weights` of the same shape as the number of features + 1. The **\"+ 1\"** extra term is for the bias weight. For now, fill the weights with some initial value (1.0 would be resonable choice to start). We'll fix that later. Remember that in our Perceptron model from above, the bias weight term is the first value in the list of weights.\n",
    "  - it creates a constant bias value `bias`, with 1 as the default\n",
    "\n",
    "- The class needs a `predict` method which takes a single argument, an array of features from a **single example** in the data set. It will do the following:\n",
    "   - multipy (*as a dot product*) the argument feature vector and the weights\n",
    "   - multiply the bias by its weight. Add that to the result.\n",
    "   - Apply the activation to the result to say whether the class of that input is -1 vs 1\n",
    "   - return that predicted class value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## finish the skeleton code below:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Perceptron():\n",
    "\n",
    "    def __init__ (self, labeled_data):        \n",
    "        # set three data attributes: data, weights, bias\n",
    "        \n",
    "        self.data= np.array(labeled_data)\n",
    "        self.weights=np.ones(self.data.shape[1]+1)\n",
    "        self.bias = 1\n",
    "        \n",
    "    def predict(self, feature_set):\n",
    "        # predict a single result for one data point.\n",
    "        # should be the dot product of features * weights + (bias * bias_weght)\n",
    "        # return 1 if the result is > 0 and -1 of it isn't\n",
    "        bias_weight= self.bias * self.weights\n",
    "        pred= np.dot(self.data, self.weights[1:])[0] + self.bias * bias_weight[0]\n",
    "        \n",
    "        if pred > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Do This:** Run the following code to test your new Perceptron class. See if it works, even though it is not yet a very good classifier. Iterate on your class until the output from this cell makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights:  [1. 1. 1. 1.]\n",
      "bias:  1\n",
      "prediction:  1\n",
      "[[ 5.1  3.5  1. ]\n",
      " [ 4.9  3.   1. ]\n",
      " [ 4.7  3.2  1. ]\n",
      " [ 4.6  3.1  1. ]\n",
      " [ 5.   3.6  1. ]\n",
      " [ 5.4  3.9  1. ]\n",
      " [ 4.6  3.4  1. ]\n",
      " [ 5.   3.4  1. ]\n",
      " [ 4.4  2.9  1. ]\n",
      " [ 4.9  3.1  1. ]\n",
      " [ 5.4  3.7  1. ]\n",
      " [ 4.8  3.4  1. ]\n",
      " [ 4.8  3.   1. ]\n",
      " [ 4.3  3.   1. ]\n",
      " [ 5.8  4.   1. ]\n",
      " [ 5.7  4.4  1. ]\n",
      " [ 5.4  3.9  1. ]\n",
      " [ 5.1  3.5  1. ]\n",
      " [ 5.7  3.8  1. ]\n",
      " [ 5.1  3.8  1. ]\n",
      " [ 5.4  3.4  1. ]\n",
      " [ 5.1  3.7  1. ]\n",
      " [ 4.6  3.6  1. ]\n",
      " [ 5.1  3.3  1. ]\n",
      " [ 4.8  3.4  1. ]\n",
      " [ 5.   3.   1. ]\n",
      " [ 5.   3.4  1. ]\n",
      " [ 5.2  3.5  1. ]\n",
      " [ 5.2  3.4  1. ]\n",
      " [ 4.7  3.2  1. ]\n",
      " [ 4.8  3.1  1. ]\n",
      " [ 5.4  3.4  1. ]\n",
      " [ 5.2  4.1  1. ]\n",
      " [ 5.5  4.2  1. ]\n",
      " [ 4.9  3.1  1. ]\n",
      " [ 5.   3.2  1. ]\n",
      " [ 5.5  3.5  1. ]\n",
      " [ 4.9  3.1  1. ]\n",
      " [ 4.4  3.   1. ]\n",
      " [ 5.1  3.4  1. ]\n",
      " [ 5.   3.5  1. ]\n",
      " [ 4.5  2.6  1. ]\n",
      " [ 4.4  3.2  1. ]\n",
      " [ 5.   3.5  1. ]\n",
      " [ 5.1  3.8  1. ]\n",
      " [ 4.8  3.   1. ]\n",
      " [ 5.1  3.8  1. ]\n",
      " [ 4.6  3.2  1. ]\n",
      " [ 5.3  3.7  1. ]\n",
      " [ 5.   3.3  1. ]\n",
      " [ 7.   3.2 -1. ]\n",
      " [ 6.4  3.2 -1. ]\n",
      " [ 6.9  3.1 -1. ]\n",
      " [ 5.5  2.3 -1. ]\n",
      " [ 6.5  2.8 -1. ]\n",
      " [ 5.7  2.8 -1. ]\n",
      " [ 6.3  3.3 -1. ]\n",
      " [ 4.9  2.4 -1. ]\n",
      " [ 6.6  2.9 -1. ]\n",
      " [ 5.2  2.7 -1. ]\n",
      " [ 5.   2.  -1. ]\n",
      " [ 5.9  3.  -1. ]\n",
      " [ 6.   2.2 -1. ]\n",
      " [ 6.1  2.9 -1. ]\n",
      " [ 5.6  2.9 -1. ]\n",
      " [ 6.7  3.1 -1. ]\n",
      " [ 5.6  3.  -1. ]\n",
      " [ 5.8  2.7 -1. ]\n",
      " [ 6.2  2.2 -1. ]\n",
      " [ 5.6  2.5 -1. ]\n",
      " [ 5.9  3.2 -1. ]\n",
      " [ 6.1  2.8 -1. ]\n",
      " [ 6.3  2.5 -1. ]\n",
      " [ 6.1  2.8 -1. ]\n",
      " [ 6.4  2.9 -1. ]\n",
      " [ 6.6  3.  -1. ]\n",
      " [ 6.8  2.8 -1. ]\n",
      " [ 6.7  3.  -1. ]\n",
      " [ 6.   2.9 -1. ]\n",
      " [ 5.7  2.6 -1. ]\n",
      " [ 5.5  2.4 -1. ]\n",
      " [ 5.5  2.4 -1. ]\n",
      " [ 5.8  2.7 -1. ]\n",
      " [ 6.   2.7 -1. ]\n",
      " [ 5.4  3.  -1. ]\n",
      " [ 6.   3.4 -1. ]\n",
      " [ 6.7  3.1 -1. ]\n",
      " [ 6.3  2.3 -1. ]\n",
      " [ 5.6  3.  -1. ]\n",
      " [ 5.5  2.5 -1. ]\n",
      " [ 5.5  2.6 -1. ]\n",
      " [ 6.1  3.  -1. ]\n",
      " [ 5.8  2.6 -1. ]\n",
      " [ 5.   2.3 -1. ]\n",
      " [ 5.6  2.7 -1. ]\n",
      " [ 5.7  3.  -1. ]\n",
      " [ 5.7  2.9 -1. ]\n",
      " [ 6.2  2.9 -1. ]\n",
      " [ 5.1  2.5 -1. ]\n",
      " [ 5.7  2.8 -1. ]]\n"
     ]
    }
   ],
   "source": [
    "## get data from file, just using file and string ops\n",
    "f = open(\"binary-iris.csv\")\n",
    "header = next(f) # dump the header line\n",
    "data = []\n",
    "for line in f:\n",
    "    fields = line.split(\",\")\n",
    "    # need to strip label because, as the last element, it has a \\n\n",
    "    label = (1.0 if fields[2].strip() == \"Iris-setosa\" else -1.0)\n",
    "    # the fields are strings until we conver them\n",
    "    data.append([float(fields[0]), float(fields[1]), label])\n",
    "f.close()\n",
    "\n",
    "p = Perceptron(data)\n",
    "print(\"weights: \", p.weights)\n",
    "print(\"bias: \", p.bias)\n",
    "print(\"prediction: \",p.predict([0,0])) # some arbitrary feature vector, just testing here\n",
    "print(p.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning\n",
    "\n",
    "OK, now the interesting part. **We need to learn the value of the weights, including the value of the bias weight, so that the predictions the `predict` method makes are good**. How to do that?\n",
    "\n",
    "The basic idea is this. We feed in the data that we have where we know the labels (and we do) to `predict`. We then compare the classification we want (from the existing data) and the classification we got (from the `predict` method). We use that difference to update **all the weights**. We do this for **each** of the data. \n",
    "\n",
    "However, we need to do one more thing. We need to not **over correct** the weights. If we do that then the weight values might swing wildly over time and never settle down. So we also provide a `learning_rate`. This rate reduces how much the weight changes. Overall then we use the following equation:\n",
    "\n",
    "$$ self.weights[i] = self.weights[i] +  self.learning\\_rate * (class\\_label - prediction\\_label) * feature[i] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do this for each feature/input of the example and each corresponding weight. We also include the bias weight. We do this for some number of iterations because, with a small `learning_rate`, we need to repeat the process to get the weight values correctly set. We also update the bias weight each time we update a weight. We use the same difference, `class_label-prediction_label` for that update (even though there is no feature value for the bias). If `weights[0]` is the bias weight, then that equation would be\n",
    "\n",
    "$$ self.weights[0] = self.weights[0] + learning\\_rate * (class\\_label - prediction\\_ label) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify our Perceptron class\n",
    "\n",
    "We need to update our `Perceptron` class to deal with learning.\n",
    "\n",
    "&#9989; **Do This:** Copy the class you wrote from above in the cell below and make the following changes:\n",
    "\n",
    "- `__init__` besides labeled data, it takes two more parameters: the **number of iterations of learning** you want and the **learning_rate**. These should be also stored as instance variables.\n",
    "- a method called `fit`. It performs the number of iterations of learning provided in `__init__` on all the labeled data as described\n",
    "- method called `errors`. It will print out the number of errors on predicted vs actual class labels and the weights at the end of the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill in the skeleton\n",
    "\n",
    "class Perceptron():\n",
    "\n",
    "    def __init__ (self, labeled_data, iters, learning_rate):  \n",
    "        self.data= np.array(labeled_data)\n",
    "        self.weights=np.ones(self.data.shape[1])\n",
    "        self.bias = 1\n",
    "        self.iters= iters\n",
    "        self.l_r= learning_rate\n",
    "        \n",
    "        \n",
    "    def predict(self, feature_set):\n",
    "        bias_weight= self.bias * self.weights\n",
    "        pred= np.dot(feature_set, self.weights[1:]) + self.bias * bias_weight[0]\n",
    "        \n",
    "        if pred > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "    def fit(self):\n",
    "        for i in range(self.iters):\n",
    "            for row in self.data:\n",
    "                update = self.l_r * (row[2] - self.predict(row[:2]))\n",
    "                self.weights[1:] += update * row[:2]\n",
    "                self.weights[0] += update\n",
    "                \n",
    "\n",
    "    \n",
    "\n",
    "    def errors(self):\n",
    "        # how many rows of the data don't match the provided label?\n",
    "        count=0\n",
    "        for row in self.data:\n",
    "            vals =self.predict(row[:2])\n",
    "            if row[2] == vals:\n",
    "                continue\n",
    "            else:\n",
    "                count +=1\n",
    "        print(count, self.weights[1:])\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        # delete this line when you add your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Do This:** Test your code with the provided code below. Change the number of iterations, the learning rate, and see what happens. Make sure `errors` prints out the weights as you will need them below. It might be useful to write a loop or two to explore how your number of errors changes as you modify the number of iterations or the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [-0.76   1.108]\n"
     ]
    }
   ],
   "source": [
    "f = open(\"binary-iris.csv\")\n",
    "header = next(f) # dump the header line\n",
    "data = []\n",
    "for line in f:\n",
    "    fields = line.split(\",\")\n",
    "    # need to strip label because, as the last element, it has a \\n\n",
    "    label = (1.0 if fields[2].strip() == \"Iris-setosa\" else -1.0)\n",
    "    # the fields are strings until we conver them\n",
    "    data.append([float(fields[0]), float(fields[1]), label])\n",
    "f.close()\n",
    "\n",
    "p = Perceptron(data, 100, 0.01)\n",
    "p.fit()\n",
    "p.errors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"viz\"></a>\n",
    "## 4. Visualing our results: plotting the decision boundary\n",
    "\n",
    "At this point, if you feel like your Perceptron class is working as intended, we can try and visualize this.\n",
    "\n",
    "Once we have run our algorithm, we can try and plot the decision boundary as well as the data entries.\n",
    "\n",
    "To make this happen, let's do some more math! **Remember** the actual bias is the bias constant you used times the bias weight (typically the first weight)\n",
    "\n",
    "Our basic calculation is $w \\cdot x + b = 0 $ where `w` and `x` are vectors and the operation \"$\\cdot$\" is the dot product. Since this is in two dimensions (two features for an input), we can rewrite this as: $w_1 * x_1 + w_2 * x_2 + b = 0$. \n",
    "\n",
    "That looks a lot like an equation of a line in the form of $Ax + By - C = 0$ if we assume $x_1 == x$ and $x_2 == y$. Let's isolate the x and y intercept:\n",
    "\n",
    "$ x = \\frac{-(b - w_2*y)}{w_1} $ but if $y=0$ (which it does at the x intercept) then $x = \\frac{-b}{w_1}$\n",
    "\n",
    "$ y = \\frac{-(b - w_1*x)}{w_2}$ but if $x=0$ (which it does at the y intercept) then $y = \\frac{-b}{w_2}$\n",
    "\n",
    "We get the following then:\n",
    "\n",
    "$slope = -\\frac{w_1}{w_2}$ and $intercept = \\frac{-b}{w_2}$\n",
    "\n",
    "Plug in your weights and plot the line. Plot the data as well where they are colored to indicate which class they belong to.\n",
    "\n",
    "The data should be stored in the `Perceptron` instance. Get the weights (which `error` should print out) and plot the line. The separate the two classes and plot each as a different color.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code here to plot the decision boundary. Use the weights from your solution above!\n",
    "v=[]\n",
    "x=[]\n",
    "for i in range(8):\n",
    "    line= (-p.weights[0]/p.weights[2] + -p.weights[1]/p.weights[2]*i)\n",
    "    v.append(line)\n",
    "    x.append(i)\n",
    "        \n",
    "\n",
    "\n",
    "plt.plot(x, v)\n",
    "plt.plot()\n",
    "for name, group in grouped:\n",
    "    plt.scatter(group.sepal_length, group.sepal_width, marker='o', label=name)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Congratulations, we're done!\n",
    "\n",
    "Now, you just need to submit this assignment by uploading it to the course <a href=\"https://d2l.msu.edu/\">Desire2Learn</a> web page for today's submission folder (Don't forget to add your names in the first cell).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#169; Copyright Michigan State University Board of Trustees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
